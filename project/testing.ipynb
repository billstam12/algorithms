{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67aba9e-c44a-4cfe-bad5-d3f3e197f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from time import time\n",
    "import itertools\n",
    "from itertools import islice, chain\n",
    "from struct import *\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import errno\n",
    "import math\n",
    "import subprocess\n",
    "\n",
    "# import pickle\n",
    "import dill as pickle \n",
    "import gffutils\n",
    "import pysam\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from collections import defaultdict\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# from modules import create_splice_graph as splice_graph\n",
    "# from modules import graph_chainer \n",
    "\n",
    "from uLTRA.modules import create_augmented_gene as augmented_gene \n",
    "from uLTRA.modules import mem_wrapper \n",
    "from uLTRA.modules import colinear_solver \n",
    "from uLTRA.modules import help_functions\n",
    "from uLTRA.modules import classify_read_with_mams\n",
    "from uLTRA.modules import classify_alignment2\n",
    "from uLTRA.modules import sam_output\n",
    "from uLTRA.modules import align\n",
    "from uLTRA.modules import prefilter_genomic_reads\n",
    "\n",
    "from new_modules import functions\n",
    "from new_modules import evaluate_exons\n",
    "from new_modules import evaluate_splice_annotations\n",
    "from new_modules import get_diff_loc_reads\n",
    "from uLTRA.evaluation import plot_correctness_per_exon_size\n",
    "from uLTRA.evaluation import plots\n",
    "from uLTRA.evaluation import venn_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45112657-344a-48e9-b71b-d542a29be327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_modules.arguments import arguments\n",
    "\n",
    "def initialize_dump(outfolder):\n",
    "    if os.path.exists(outfolder) and os.path.isdir(outfolder):\n",
    "        shutil.rmtree(outfolder)\n",
    "    help_functions.mkdir_p(outfolder)\n",
    "    \n",
    "def create_args(ref, gtf, bed, reads, ont, isoseq, disable_infer, name, tool_name, mm2, desalt_index):\n",
    "    args = arguments(ref, gtf, bed, reads, ont, isoseq, disable_infer, name, tool_name, mm2, desalt_index)\n",
    "    s = args.reads\n",
    "    s = s[s.rindex('/')+1:]\n",
    "    s = s[:s.rindex('.')]\n",
    "    args.name = s\n",
    "    if args.ont:\n",
    "        args.min_mem = 17\n",
    "        args.min_acc = 0.6\n",
    "        args.mm2_ksize = 14\n",
    "        # args.alignment_threshold = 0.5\n",
    "    if args.isoseq:\n",
    "        args.min_mem = 20\n",
    "        args.min_acc = 0.8\n",
    "        # args.alignment_threshold = 0.5\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866cb84c-0f0a-48e1-abfd-ec369fdc045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_desalt_args(args):\n",
    "    d = 10 \n",
    "    s = 2\n",
    "    l = 14\n",
    "    noncan = 9\n",
    "    max_intron_length = 500000\n",
    "    index_path = args.desalt_index\n",
    "    \n",
    "    if(args.gtf == None):\n",
    "        if(\"SIRV\" in args.ref):\n",
    "            noncan = 4\n",
    "            max_intron_length = 200000\n",
    "            return [\"desalt\", \"aln\", index_path, args.reads, \n",
    "                               \"-d\", str(d), \"-s\", str(s),\n",
    "                                \"--noncan\", str(noncan), \"--max-intron-len\", str(max_intron_length),\n",
    "                    \"-o\", os.path.join(args.outfolder, \"reads.sam\")]\n",
    "        else:\n",
    "            return [\"desalt\", \"aln\", index_path, args.reads, \n",
    "                               \"-d\", str(d), \"-s\", str(s),\n",
    "                                \"--noncan\", str(noncan), \"--max-intron-len\", str(max_intron_length),\n",
    "                    \"-o\", os.path.join(args.outfolder, \"reads.sam\")]\n",
    "    else:\n",
    "        if(\"SIRV\" in args.ref):\n",
    "            noncan = 4\n",
    "            max_intron_length = 200000\n",
    "            return [\"desalt\", \"aln\", index_path, args.reads, \n",
    "                               \"-d\", str(d), \"-s\", str(s),\n",
    "                                \"--noncan\", str(noncan), \"--max-intron-len\", str(max_intron_length),\n",
    "                                \"--gtf\", args.gtf,\n",
    "                                \"-o\", os.path.join(args.outfolder, \"reads.sam\")]\n",
    "        else:\n",
    "            return [\"desalt\", \"aln\", index_path, args.reads, \n",
    "                               \"-d\", str(d), \"-s\", str(s),\n",
    "                                \"--noncan\", str(noncan), \"--max-intron-len\", str(max_intron_length),\n",
    "                                \"--gtf\", args.gtf,\n",
    "                                \"-o\", os.path.join(args.outfolder, \"reads.sam\")]\n",
    "\n",
    "\n",
    "def deSALT(args):\n",
    "    reads = os.path.join(args.outfolder, \"reads.sam\")\n",
    "    if (not os.path.exists(reads)):\n",
    "        stats = {}\n",
    "        stats[\"dataset\"] = args.name\n",
    "        initialize_dump(args.outfolder)\n",
    "        deSALT_start = time()\n",
    "        if not os.path.exists(args.desalt_index): \n",
    "            subprocess.check_call([\"desalt\", \"index\",args.ref, os.path.join(args.outfolder, \"index\")])\n",
    "        subprocess.check_call(set_desalt_args(args), env = os.environ)\n",
    "        stats[\"total_time\"] = time() - deSALT_start\n",
    "        json.dump(stats, open(os.path.join(args.outfolder, \"stats.json\"), \"w\"))\n",
    "\n",
    "\n",
    "    subprocess.check_call([\"desalt\", \"aln\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e85fc44-0144-462d-9f20-a1aef6a96cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict with the paths of each dataset\n",
    "dataset_dict = {\n",
    "    # \"test\" : {\n",
    "    #     \"ref\": \"uLTRA/test/SIRV_genes.fasta\" ,\n",
    "    #     \"reads\": \"uLTRA/test/reads.fa\" ,\n",
    "    #     \"gtf\": \"uLTRA/test/SIRV_genes_C_170612a.gtf\" ,\n",
    "    #     \"bed\":\"uLTRA/test/SIRV_genes_C_170612a.bed\",\n",
    "    #     \"ont\": False,\n",
    "    #     \"isoseq\": True,\n",
    "    #     \"disable_infer\": False,\n",
    "    # },\n",
    "     \"DROS\": {\"ref\": \"data/genome/DROS/DROS.BDGP6.28.all.fa\",\n",
    "            \"reads\": \"data/DROS/DROS_processed.fastq\",\n",
    "            \"gtf\": \"data/genome/annotations/Drosophila_melanogaster.BDGP6.28.102.gtf\",\n",
    "            \"bed\":\"data/genome/annotations/bed/Drosophila_melanogaster.BDGP6.28.102.bed\",\n",
    "            \"desalt_index\":\"data/genome/indexes/dmIndex\",\n",
    "            \"ont\": True,\n",
    "            \"isoseq\": False,\n",
    "            \"disable_infer\": True,\n",
    "            \"desalt_index\":\"data/genome/indexes/dm\",   \n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc1bc98e-8d51-49de-aae8-eac2ea7d5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_pipeline(dataset):\n",
    "    category_stats = {\"uLTRA\" :{}, \"uLTRA_mm2\" :{}, \"minimap2\" :{}, \"minimap2_GTF\" :{}, \"deSALT\" :{}, \"deSALT_GTF\" :{}}\n",
    "    \n",
    "    ref = dataset[\"ref\"]\n",
    "    gtf = dataset[\"gtf\"]\n",
    "    bed = dataset[\"bed\"]\n",
    "    reads = dataset[\"reads\"]\n",
    "    ont = dataset[\"ont\"]\n",
    "    isoseq = dataset[\"isoseq\"]\n",
    "    disable_infer = dataset[\"disable_infer\"]\n",
    "    desalt_index = dataset[\"desalt_index\"]\n",
    "    \n",
    "    # ultra\n",
    "    toolname = \"deSALT\"\n",
    "    args = create_args(ref, None, bed, reads, ont, isoseq, disable_infer, dataset_name, toolname, True, desalt_index)\n",
    "    deSALT(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05291cb6-3bdd-47b0-89a7-ae6f5973769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating output/DROS/deSALT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Main] deSALT - De Bruijn graph-based Spliced Aligner for Long Transcriptome reads\n",
      "[Param-INFO] deSALT parameters:index-kmer:22\tseed-lmer:15\thash-kmer:8\tthread:4\tstrand_diff:10\tidentify junction:both_strand\n",
      "[Phase-INFO] Loading Index and Reads\n",
      "[Phase-INFO] Seeding and Chaining Phase (first-pass)\n",
      "[Skeleton-generation] Generating skeletons of 655350 reads, total 413218919 bases in 31.866877 seconds\n",
      "[Skeleton-generation] Generating skeletons of 655350 reads, total 435255562 bases in 29.593379 seconds\n",
      "[Skeleton-generation] Generating skeletons of 155782 reads, total 103536043 bases in 7.059926 seconds\n",
      "[Phase-INFO] Total 1466482 reads were processed in 68.532 seconds (first-pass)\n",
      "[Phase-INFO] Refined Alignment Phase (second-pass)\n",
      "[Phase-INFO] Exons inference by skeletons of all reads\n",
      "[Phase-INFO] Inferring total 56690 isolated regions (pseudo-exons) after merging and filtering\n",
      "[Phase-INFO] Refining pseudo-exons by scoring matrix\n",
      "[Loop-ProcessReads] The 0st loop of refined alignment procedure with 293298 reads......\n",
      "[Loop-ProcessReads] Aligned 267312 reads to genome, and confirmed total 22947 exons' strand in 72.331730 seconds\n",
      "[Loop-ProcessReads] The 1st loop of refined alignment procedure with 293298 reads......\n",
      "[Loop-ProcessReads] Aligned 276408 reads to genome, and confirmed total 29108 exons' strand in 57.445513 seconds\n",
      "[Loop-ProcessReads] The 2st loop of refined alignment procedure with 293298 reads......\n",
      "[Loop-ProcessReads] Aligned 277657 reads to genome, and confirmed total 32871 exons' strand in 56.360656 seconds\n",
      "[Loop-ProcessReads] The 3st loop of refined alignment procedure with 293298 reads......\n",
      "[Loop-ProcessReads] Aligned 276382 reads to genome, and confirmed total 35432 exons' strand in 55.609542 seconds\n",
      "[Loop-ProcessReads] The 4st loop of refined alignment procedure with 293290 reads......\n",
      "[Loop-ProcessReads] Aligned 274949 reads to genome, and confirmed total 37714 exons' strand in 61.738389 seconds\n",
      "[Phase-INFO] Total 1372708 reads were mapped to genome in 318.873851 seconds (second-pass)\n",
      "[Phase-INFO] Finishing Alignment\n",
      "[Phase-INFO] Command: @PG\tID:deSALT\tPN:deSALT\tVN:1.5.6\tCL:desalt aln data/genome/indexes/dm data/DROS/DROS_processed.fastq -d 10 -s 2 --noncan 9 --max-intron-len 500000 -o output/DROS/deSALT/reads.sam\n",
      "[Main] Real time: 389.927 sec; CPU: 1445.941 sec, Memory peak: 4190.84 GB\n",
      "[Main] deSALT - De Bruijn graph-based Spliced Aligner for Long Transcriptome reads\n",
      "\n",
      "Program:\tde Brijn Graph-based 3rd RNA sequence alignment\n",
      "Usage:\t\tdeSALT aln [options] -f <temporary file> <index_route> <read.fa/fq>\n",
      "\n",
      "    -f <temporary file>           The temporary file for storing alignment skeletons in first pass.\n",
      "                                  If users run two deSALT program in the same time, -f option is necessary.\n",
      "    <index_route>                 The path of RdBG index.\n",
      "    <read.fq/fa>                  The input reads in fasta or fastq format.\n",
      "\n",
      "Algorithm options:\n",
      "\n",
      "    -t --thread           [INT]    Number of threads. [4]\n",
      "    -k --index-kmer       [INT]    K-mer length of RdBG-index. [22]\n",
      "    -l --seeding-lmer     [INT]    K-mer length of seeding process (no long than RdBG-index). [15]\n",
      "    -a --local-hash-kmer  [INT]    K-mer length of local hash process. [8]\n",
      "    -s --seed-step        [INT]    The interval of seeding. [5]\n",
      "    -B --batch-size       [INT]    The number of reads to be processed in one loop. [100000]\n",
      "    -n --max-uni-pos      [INT]    Maximum allowed number of hits per seed. [50]\n",
      "    -L --max-readlen      [INT]    Maximum allowed read length. [1000000]\n",
      "    -i --min-frag-dis     [INT]    Maximum allowed distance of two fragment can be connect. [20]\n",
      "    -I --max-intron-len   [INT]    maximum allowed intron length. [200000]\n",
      "    -c --min-chain-score  [INT]    minimal skeleton score(match bases minus gap penalty). [20]\n",
      "    -d --strand-diff      [INT]    The minimal difference of dp score by two strand to make sure the transcript strand. [20]\n",
      "    -g --max-read-gap     [INT]    Maximum allowed gap in read when chaining. [2000]\n",
      "    -p --secondary-ratio  [FLOAT]  Min secondary-to-primary score ratio. [0.90]\n",
      "    -e --e-shift          [INT]    The number of downstream (upstream) exons will be processed when left (right) extension. [5]\n",
      "    -T --trans-strand              Find splicing site according to transcript strand\n",
      "    -G --gtf              [STR]    Provided annotation information for precise intron donor and acceptor sites.\n",
      "                                   Convert GTF file(now support GTF format only) to fixed format of deSALT by Annotation_Load.py \n",
      "    -x --read-type        [STR]    Specifiy the type of reads and set multiple paramters unless overriden.\n",
      "                                   [null] default parameters.\n",
      "                                   ccs (PacBio SMRT CCS reads): error rate 1%\n",
      "                                   clr (PacBio SMRT CLR reads): error rate 15%\n",
      "                                   ont1d (Oxford Nanopore 1D reads): error rate > 20%\n",
      "                                   ont2d (Oxford Nanopore 2D reads): error rate > 12%\n",
      "\n",
      "Scoring options\n",
      "\n",
      "    -O --open-pen         [INT(,INT)]\n",
      "                                   Gap open penealty. [2,32]\n",
      "    -E --ext-pen          [INT(,INT)]\n",
      "                                   Gap extension penalty; a k-long gap costs min{O1+k*E1,O2+k*E2}. [1,0]\n",
      "    -m --match-score      [INT]    Match score for SW-alginment. [1]\n",
      "    -M --mis-score        [INT]    Mismatch score for SW-alignment. [2]\n",
      "    -z --zdrop            [INT(,INT)]\n",
      "                                   Z-drop score for splice/non-splice alignment. [400]\n",
      "    -w --band-width       [INT]    Bandwidth used in chaining and DP-based alignment. [500]\n",
      "    -R --noncan           [INT]    Penalty score for non-canonical splice junction sites. [9]\n",
      "\n",
      "Output options\n",
      "\n",
      "    -N --top-num-aln      [INT]    Max allowed number of secondary alignment. [4]\n",
      "    -Q --without-qual              Don't output base quality in SAM\n",
      "    -f --temp-file-perfix [STR]    Route of temporary files after the first-pass alignment. [1pass_anchor]\n",
      "                                   If you run more than one deSALT program in the same time, \n",
      "                                   you must point out different routes of temporary files for each program!!!\n",
      "                                   If no, every deSALT program will write temporary data to the same file which \n",
      "                                   will cause crash of program in 2-pass alignment due to inconsistent temporary data.\n",
      "    -o --output           [STR]    Output file (SAM format). [./aln.sam]\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_dict.keys():\n",
    "    dataset = dataset_dict[dataset_name]\n",
    "    is_real = dataset[\"ont\"] or dataset[\"isoseq\"] # if the dataset is real\n",
    "    if is_real:\n",
    "        real_data_pipeline(dataset)\n",
    "    else:\n",
    "        sim_data_pipeline(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f3f5e-a53a-4fd2-ac64-7d04fabaf924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
